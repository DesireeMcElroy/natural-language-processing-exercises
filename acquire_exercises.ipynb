{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Codeup Blog Articles\n",
    "\n",
    "Scrape the article text from the following pages:\n",
    "\n",
    " - https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    " - https://codeup.com/data-science-myths/\n",
    " - https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\n",
    " - https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\n",
    " - https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\n",
    " \\\n",
    "Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries, with each dictionary representing one article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles(url):\n",
    "    '''\n",
    "    This function takes in a url and pull the necessary elements off the website\n",
    "    then creates a dictionary with those elements\n",
    "    '''\n",
    "\n",
    "    # create an empty dictionary to append to\n",
    "    blog_dict = {}\n",
    "    \n",
    "    # fetch the data\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    # pull the elements from the soup\n",
    "    article = soup.find('div', class_='jupiterx-post-content') # pulling body of text\n",
    "    title = soup.find('h1', class_='jupiterx-post-title') # pulling title as text\n",
    "    \n",
    "    # append the elements to the dictionary\n",
    "    blog_dict = {'title': title.text,\n",
    "                'content': article.text}\n",
    "    \n",
    "    # return dictionary\n",
    "    return blog_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my list of urls\n",
    "url_list = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "           'https://codeup.com/data-science-myths/',\n",
    "           'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "           'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "           'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']\n",
    "\n",
    "# create an empty list\n",
    "list_of_blogs=[]\n",
    "\n",
    "# create a for loop for all the urls in the list to pull elements from and return a dict\n",
    "for url in url_list:\n",
    "    list_of_blogs.append(get_blog_articles(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Codeup’s Data Science Career Accelerator is Here!',\n",
       " 'content': 'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the first entry in the dictionary\n",
    "list_of_blogs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. News Articles\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "- Business\n",
    "- Sports\n",
    "- Technology\n",
    "- Entertainment\n",
    "\n",
    "\n",
    "The end product of this should be a function named get_news_articles that returns a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]\n",
    "\n",
    "base_url = 'https://inshorts.com/en/read/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(article, category):\n",
    "    # Attribute selector\n",
    "    title = article.select(\"[itemprop='headline']\")[0].text\n",
    "    \n",
    "    # article body\n",
    "    content = article.select(\"[itemprop='articleBody']\")[0].text\n",
    "    \n",
    "    output = {}\n",
    "    output[\"title\"] = title\n",
    "    output[\"content\"] = content\n",
    "    output[\"category\"] = category\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(category, base =\"https://inshorts.com/en/read/\"):\n",
    "    \"\"\"\n",
    "    This function takes in a category as a string. Category must be an available category in inshorts\n",
    "    Returns a list of dictionaries where each dictionary represents a single inshort article\n",
    "    \"\"\"\n",
    "    \n",
    "    # We concatenate our base_url with the category\n",
    "    url = base + category\n",
    "    \n",
    "    # Set the headers\n",
    "    headers = {\"User-Agent\": \"Mozilla/4.5 (compatible; HTTrack 3.0x; Windows 98)\"}\n",
    "\n",
    "    # Get the http response object from the server\n",
    "    response = get(url, headers=headers)\n",
    "\n",
    "    # Make soup out of the raw html\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    # Ignore everything, focusing only on the news cards\n",
    "    articles = soup.select(\".news-card\")\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    # Iterate through every article tag/soup \n",
    "    for article in articles:\n",
    "        \n",
    "        # Returns a dictionary of the article's title, body, and category\n",
    "        article_data = get_article(article, category) \n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        output.append(article_data)\n",
    "    \n",
    "    # Return the list of dictionaries\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"China's ex-teacher turned billionaire no more a billionaire as shares fall 98%\",\n",
       " 'content': \"China's Larry Chen, a former teacher who became a billionaire with edtech company Gaotu Techedu, lost his billionaire status after his company's shares fell 98%. Chen, Gaotu Techedu's Founder and CEO, is now worth $336 million according to Bloomberg. The development comes as China's new regulations banned companies teaching school curriculums from making profits, raising capital or going public.\",\n",
       " 'category': 'business'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles = get_articles('business', base =\"https://inshorts.com/en/read/\")\n",
    "news_articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news_articles(categories):\n",
    "    \"\"\"\n",
    "    Takes in a list of categories where the category is part of the URL pattern on inshorts\n",
    "    Returns a dataframe of every article from every category listed\n",
    "    Each row in the dataframe is a single article\n",
    "    \"\"\"\n",
    "    all_inshorts = []\n",
    "\n",
    "    for category in categories:\n",
    "        all_category_articles = get_articles(category)\n",
    "        all_inshorts = all_inshorts + all_category_articles\n",
    "\n",
    "    df = pd.DataFrame(all_inshorts)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon job posting fuels speculations about pl...</td>\n",
       "      <td>A new job posting by Amazon has fuelled specul...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China's ex-teacher turned billionaire no more ...</td>\n",
       "      <td>China's Larry Chen, a former teacher who becam...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk takes a jibe at rival car companies, says...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Govt paid Infosys ₹164.5 crore for new Income ...</td>\n",
       "      <td>The government paid ₹164.5 crore to Infosys to...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment rate rises in both urban, rural a...</td>\n",
       "      <td>India's unemployment rate soared to 7.14% in t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Afghan Army chief postpones India visit amid T...</td>\n",
       "      <td>Afghan Army chief General Wali Mohammad Ahmadz...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>46 Afghan soldiers flee to Pakistan in retreat...</td>\n",
       "      <td>The Pakistani Army on Monday said that 46 Afgh...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>UAE extends ban on passenger flights from Indi...</td>\n",
       "      <td>The UAE has extended a ban on passenger flight...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Man accused of trying to kill Mali's interim P...</td>\n",
       "      <td>A man accused of trying to kill Mali's interim...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Lebanese lawmakers pick billionaire Najib Mika...</td>\n",
       "      <td>Lebanese lawmakers during parliamentary consul...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Amazon job posting fuels speculations about pl...   \n",
       "1    China's ex-teacher turned billionaire no more ...   \n",
       "2    Musk takes a jibe at rival car companies, says...   \n",
       "3    Govt paid Infosys ₹164.5 crore for new Income ...   \n",
       "4    Unemployment rate rises in both urban, rural a...   \n",
       "..                                                 ...   \n",
       "142  Afghan Army chief postpones India visit amid T...   \n",
       "143  46 Afghan soldiers flee to Pakistan in retreat...   \n",
       "144  UAE extends ban on passenger flights from Indi...   \n",
       "145  Man accused of trying to kill Mali's interim P...   \n",
       "146  Lebanese lawmakers pick billionaire Najib Mika...   \n",
       "\n",
       "                                               content  category  \n",
       "0    A new job posting by Amazon has fuelled specul...  business  \n",
       "1    China's Larry Chen, a former teacher who becam...  business  \n",
       "2    Tesla CEO and the world's second-richest perso...  business  \n",
       "3    The government paid ₹164.5 crore to Infosys to...  business  \n",
       "4    India's unemployment rate soared to 7.14% in t...  business  \n",
       "..                                                 ...       ...  \n",
       "142  Afghan Army chief General Wali Mohammad Ahmadz...     world  \n",
       "143  The Pakistani Army on Monday said that 46 Afgh...     world  \n",
       "144  The UAE has extended a ban on passenger flight...     world  \n",
       "145  A man accused of trying to kill Mali's interim...     world  \n",
       "146  Lebanese lawmakers during parliamentary consul...     world  \n",
       "\n",
       "[147 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_all_news_articles(categories)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soup.title.string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
