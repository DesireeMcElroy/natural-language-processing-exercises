{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/desireemcelroy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/desireemcelroy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = \"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed \\\n",
    "a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), \\\n",
    "but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\"\n",
    "original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and normalizes it for nlp purposes\n",
    "    '''\n",
    "    # lowercase the string\n",
    "    string = string.lower()\n",
    "    # return normal form for the unicode string, encode/remove ascii\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8')\n",
    "    # breaks down the string by keeping alphabet letters, numbers, apostraphes and spaces\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos's name contains the hungarian letter 'o' 'o' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = basic_clean(original)\n",
    "\n",
    "original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and tokenizes it\n",
    "    '''\n",
    "    # create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # use the tokenizer, return as a string\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = tokenize(original)\n",
    "\n",
    "original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    \n",
    "    # create a porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # loop through the text to stem the words\n",
    "    stems = [ps.stem(word) for word in text.split()]\n",
    "    \n",
    "    stems = ' '.join(stems)\n",
    "    \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(original)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    \n",
    "    # create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # loop through the list to split and lemmatize\n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    \n",
    "    lemmas =' '.join(lemmas)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(original)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \n",
    "    # pull the english stopwords\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # split the inputted text into a list to loop through\n",
    "    words = text.split()\n",
    "    \n",
    "    # loop through to remove stop words from the list\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    filtered_words = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(original)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desireemcelroy/codeup-data-science/natural-language-processing-exercises/acquire.py:71: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 71 of the file /Users/desireemcelroy/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]\n",
    "\n",
    "news = acquire.get_all_news_articles(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factually incorrect: INOX on report of Amazon ...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  I will most likely not be on future earnings c...   \n",
       "2  Musk criticises Apple's 'walled garden', cobal...   \n",
       "3  Speculation around our plans for crypto not tr...   \n",
       "4  Factually incorrect: INOX on report of Amazon ...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Reliance Industries has said in a statement th...  business  \n",
       "1  Tesla CEO and the world's second-richest perso...  business  \n",
       "2  Tesla's billionaire CEO Elon Musk criticised A...  business  \n",
       "3  Amazon on Monday denied speculations that it w...  business  \n",
       "4  INOX Leisure denied a report that claimed Amaz...  business  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desireemcelroy/codeup-data-science/natural-language-processing-exercises/acquire.py:21: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 21 of the file /Users/desireemcelroy/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "url_list = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "           'https://codeup.com/data-science-myths/',\n",
    "           'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "           'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "           'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']\n",
    "\n",
    "\n",
    "# create an empty list\n",
    "list_of_blogs=[]\n",
    "\n",
    "# create a for loop for all the urls in the list to pull elements from and return a dict\n",
    "for url in url_list:\n",
    "    list_of_blogs.append(acquire.get_blog_articles(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs = pd.DataFrame(list_of_blogs)\n",
    "\n",
    "blogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title - to hold the title\n",
    "- original - to hold the original article/post content\n",
    "- clean - to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed - to hold the stemmed version of the cleaned data.\n",
    "- lemmatized - to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First apply to news dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factually incorrect: INOX on report of Amazon ...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  I will most likely not be on future earnings c...   \n",
       "2  Musk criticises Apple's 'walled garden', cobal...   \n",
       "3  Speculation around our plans for crypto not tr...   \n",
       "4  Factually incorrect: INOX on report of Amazon ...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Reliance Industries has said in a statement th...  business  \n",
       "1  Tesla CEO and the world's second-richest perso...  business  \n",
       "2  Tesla's billionaire CEO Elon Musk criticised A...  business  \n",
       "3  Amazon on Monday denied speculations that it w...  business  \n",
       "4  INOX Leisure denied a report that claimed Amaz...  business  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for the news df\n",
    "\n",
    "# create a variable for the cleaned version\n",
    "clean=[] \n",
    "for i in news.content:\n",
    "  \n",
    "    normalize = basic_clean(i)\n",
    "    \n",
    "    clean.append(tokenize(normalize))\n",
    "\n",
    "# create column for cleaned content\n",
    "news['clean'] = clean\n",
    "    \n",
    "stemmed=[] \n",
    "for i in news.clean:\n",
    "  \n",
    "    stemmed.append(stem(i))\n",
    "    \n",
    "    \n",
    "lemmatized=[] \n",
    "for i in news.clean:\n",
    "  \n",
    "    lemmatized.append(lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns for stemmed and lemmatized content\n",
    "news['stemmed'] = stemmed\n",
    "news['lemmatized'] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "      <td>reliance industries has said in a statement th...</td>\n",
       "      <td>relianc industri ha said in a statement that o...</td>\n",
       "      <td>reliance industry ha said in a statement that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "      <td>tesla ceo and the world ' s secondrichest pers...</td>\n",
       "      <td>tesla ceo and the world ' s secondrichest pers...</td>\n",
       "      <td>tesla ceo and the world ' s secondrichest pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "      <td>tesla ' s billionaire ceo elon musk criticised...</td>\n",
       "      <td>tesla ' s billionair ceo elon musk criticis ap...</td>\n",
       "      <td>tesla ' s billionaire ceo elon musk criticised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "      <td>amazon on monday denied speculations that it w...</td>\n",
       "      <td>amazon on monday deni specul that it wa look t...</td>\n",
       "      <td>amazon on monday denied speculation that it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factually incorrect: INOX on report of Amazon ...</td>\n",
       "      <td>INOX Leisure denied a report that claimed Amaz...</td>\n",
       "      <td>business</td>\n",
       "      <td>inox leisure denied a report that claimed amaz...</td>\n",
       "      <td>inox leisur deni a report that claim amazon in...</td>\n",
       "      <td>inox leisure denied a report that claimed amaz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  I will most likely not be on future earnings c...   \n",
       "2  Musk criticises Apple's 'walled garden', cobal...   \n",
       "3  Speculation around our plans for crypto not tr...   \n",
       "4  Factually incorrect: INOX on report of Amazon ...   \n",
       "\n",
       "                                             content  category  \\\n",
       "0  Reliance Industries has said in a statement th...  business   \n",
       "1  Tesla CEO and the world's second-richest perso...  business   \n",
       "2  Tesla's billionaire CEO Elon Musk criticised A...  business   \n",
       "3  Amazon on Monday denied speculations that it w...  business   \n",
       "4  INOX Leisure denied a report that claimed Amaz...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  reliance industries has said in a statement th...   \n",
       "1  tesla ceo and the world ' s secondrichest pers...   \n",
       "2  tesla ' s billionaire ceo elon musk criticised...   \n",
       "3  amazon on monday denied speculations that it w...   \n",
       "4  inox leisure denied a report that claimed amaz...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  relianc industri ha said in a statement that o...   \n",
       "1  tesla ceo and the world ' s secondrichest pers...   \n",
       "2  tesla ' s billionair ceo elon musk criticis ap...   \n",
       "3  amazon on monday deni specul that it wa look t...   \n",
       "4  inox leisur deni a report that claim amazon in...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  reliance industry ha said in a statement that ...  \n",
       "1  tesla ceo and the world ' s secondrichest pers...  \n",
       "2  tesla ' s billionaire ceo elon musk criticised...  \n",
       "3  amazon on monday denied speculation that it wa...  \n",
       "4  inox leisure denied a report that claimed amaz...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now apply to blogs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the blogs df\n",
    "\n",
    "# create a variable for the cleaned version\n",
    "clean=[] \n",
    "for i in blogs.content:\n",
    "  \n",
    "    normalize = basic_clean(i)\n",
    "    \n",
    "    clean.append(tokenize(normalize))\n",
    "\n",
    "# create column for cleaned content\n",
    "blogs['clean'] = clean\n",
    "    \n",
    "stemmed=[] \n",
    "for i in blogs.clean:\n",
    "  \n",
    "    stemmed.append(stem(i))\n",
    "    \n",
    "    \n",
    "lemmatized=[] \n",
    "for i in blogs.clean:\n",
    "  \n",
    "    lemmatized.append(lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for stemmed and lemmatized versions\n",
    "blogs['stemmed'] = stemmed\n",
    "blogs['lemmatized'] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "      <td>the rumors are true the time has arrived codeu...</td>\n",
       "      <td>the rumor are true the time ha arriv codeup ha...</td>\n",
       "      <td>the rumor are true the time ha arrived codeup ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "      <td>by dimitri antoniou and maggie giust\\ndata sci...</td>\n",
       "      <td>by dimitri antoni and maggi giust data scienc ...</td>\n",
       "      <td>by dimitri antoniou and maggie giust data scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "      <td>by dimitri antoniou\\na week ago codeup launche...</td>\n",
       "      <td>by dimitri antoni a week ago codeup launch our...</td>\n",
       "      <td>by dimitri antoniou a week ago codeup launched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "      <td>sa tech job fair\\nthe third biannual san anton...</td>\n",
       "      <td>sa tech job fair the third biannual san antoni...</td>\n",
       "      <td>sa tech job fair the third biannual san antoni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>competitor bootcamps are closing is the model ...</td>\n",
       "      <td>competitor bootcamp are close is the model in ...</td>\n",
       "      <td>competitor bootcamps are closing is the model ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The rumors are true! The time has arrived. Cod...   \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...   \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...   \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  the rumors are true the time has arrived codeu...   \n",
       "1  by dimitri antoniou and maggie giust\\ndata sci...   \n",
       "2  by dimitri antoniou\\na week ago codeup launche...   \n",
       "3  sa tech job fair\\nthe third biannual san anton...   \n",
       "4  competitor bootcamps are closing is the model ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  the rumor are true the time ha arriv codeup ha...   \n",
       "1  by dimitri antoni and maggi giust data scienc ...   \n",
       "2  by dimitri antoni a week ago codeup launch our...   \n",
       "3  sa tech job fair the third biannual san antoni...   \n",
       "4  competitor bootcamp are close is the model in ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  the rumor are true the time ha arrived codeup ...  \n",
       "1  by dimitri antoniou and maggie giust data scie...  \n",
       "2  by dimitri antoniou a week ago codeup launched...  \n",
       "3  sa tech job fair the third biannual san antoni...  \n",
       "4  competitor bootcamps are closing is the model ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rumor are true the time ha arriv codeup ha offici open applic to our new data scienc career acceler with onli 25 seat avail thi immers program is one of a kind in san antonio and will help you land a job in glassdoor 1 best job in america data scienc is a method of provid action intellig from data the data revolut ha hit san antonio result in an explos in data scientist posit across compani like usaa accentur booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecur center and school of data scienc we built a program to specif meet the grow demand of thi industri our program will be 18 week long fulltim handson and projectbas our curriculum develop and instruct is led by senior data scientist maggi giust who ha work at heb capit group and rackspac along with input from dozen of practition and hire partner student will work with real data set realist problem and the entir data scienc pipelin from collect to deploy they will receiv profession develop train in resum write interview and continu educ to prepar for a smooth transit to the workforc we focu on appli data scienc for immedi impact and roi in a busi which is how we can back it all up with a 6 month tuition refund guarante just like our exist web dev program were focus on data scienc with python sql and ml cover in 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel with data and 14 domain expertis develop applic are now open for codeup first data scienc cohort which will start class on februari 4 2019 hurri there are onli 25 seat avail to further our mission of cultiv inclus growth scholarship will be avail to women minor lgbtqia individu veteran first respond and peopl reloc to san antonio if you want to learn about join our program or hire our graduat email datasciencecodeupcom'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.stemmed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rumor are true the time ha arrived codeup ha officially opened application to our new data science career accelerator with only 25 seat available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution ha hit san antonio resulting in an explosion in data scientist position across company like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demand of this industry our program will be 18 week long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who ha worked at heb capital group and rackspace along with input from dozen of practitioner and hiring partner student will work with real data set realistic problem and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 module 1 fundamental 2 applied statistic 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topic deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development application are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seat available to further our mission of cultivating inclusive growth scholarship will be available to woman minority lgbtqia individual veteran first responder and people relocating to san antonio if you want to learn about joining our program or hiring our graduate email datasciencecodeupcom'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
